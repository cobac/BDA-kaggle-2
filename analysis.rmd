---
title: meh
output: html_document
---
<!-- The ipynb exporter doesn't like the yaml part of the file -->
# Physical activity recognition - Group 6
- David Coba
- Fridtjof Petersen 
- Leonhard Volz

# Setup

```{r}
library(tidyverse) 
```

```{r}
# Switch to TRUE when submitting the notebook to Kaggle
RUN_IN_KAGGLE <- FALSE
if (RUN_IN_KAGGLE) {
  # Copy all files to the current directory
  system("cp -r ../input/bda-2021-physical-activity-recognition/* ./")
} 
```


## Importing labels

```{r}
act_labels = read_table2("activity_labels.txt", col_names = FALSE)
act_labels = act_labels %>% select(X1,X2)
act_labels 
```

```{r}
labels = read_delim("./RawData/Train/labels_train.txt", " ", col_names = F)
colnames(labels) <- c('trial', 'userid', 'activity', 'start', 'end')

labels = labels %>% mutate(activity = act_labels$X2[activity])
```

```{r}
print(labels)
```

```{r}
# Add the sequence start:end to each row in a list.
# The result is a nested table:
sample_labels_nested <- 
  labels %>% 
  rowwise() %>% # do next operation(s) rowwise
  mutate(sampleid = list(start:end)) %>%
  ungroup()

# Check the resulting table:
print(sample_labels_nested, n=6) 
```

```{r}
sample_labels <- 
  sample_labels_nested %>% 

# Rows are segments, we need to keep track of different segements
mutate(segment = row_number() ) %>% 

# Expand the data frame to one sample per row
unnest(cols = c(sampleid)) %>% 

# Remove columns we don't need anymore
select(-start, -end) 

```

# Features

## Time-domain features


<!---
Slowly changing signals have high autocorellations, while fast changing signals have low or even negative autocorrelations.
https://paper.dropbox.com/doc/Feature-extraction-from-Signals--A62tmtXDMS34X292NP0fKphQAQ-qCp5uvj47gmyuw5nmB8lL
-->

```{r}
lagged_cor <- function(x, y=x, lag=0) {
  # compute correlation between x and a time shifted y
  r_lagged = cor(x, dplyr::lag(y, lag), use='pairwise')
  return(r_lagged)
}
```

## Frequency domain features

<!---
We do not discuss frequency domain features (also known as "spectral" features) at this time, but they are described in the reading materials ([Feature extraction from Signals](https://paper.dropbox.com/doc/Feature-extraction-from-Signals--A62tmtXDMS34X292NP0fKphQAQ-qCp5uvj47gmyuw5nmB8lL)). 
-->

# Putting it all together

```{r}
# Helper functions
most_common_value = function(x) {
  counts = table(x, useNA='no')
  most_frequent = which.max(counts)
  return(names(most_frequent))
}


```
- Frequency helper functions

```{r}


peak <- function(data){
  spec = spectrum(data, log='n',plot=F)
  return(spec$freq[which.max(spec$spec)])
}

freq_mean <- function(data){
  
spec = spectrum(data, log='n', plot=FALSE)
df   = spec$freq[2] - spec$freq[1]
sbar = sum(spec$freq * spec$spec * df)               # 
return(sbar)  
}

freq_var <- function(data){
  
spec = spectrum(data, log='n', plot=FALSE)
df   = spec$freq[2] - spec$freq[1]
xbar = sum(spec$freq * spec$spec * df)  
svar = sum((spec$freq - xbar)^2 * spec$spec * df)
return(svar)  
}



```


- Extracts the time-series for the three dimensions of a sensor

```{r}
extractSignals <- function(filename, sample_labels) {
    
  # extract user and experimental run ID's from file name
  username = gsub(".+user(\\d+).+", "\\1", filename) %>% as.numeric()
  expname  = gsub( ".+exp(\\d+).+", "\\1", filename) %>% as.numeric()
  
  # import the sensor signals from the file
  user <- read_delim(filename, " ", col_names = FALSE, progress = TRUE, 
                     col_types = "ddd")
  
  # merge signals with labels 
  user_df <- 
    data.frame(userid = username, trial = expname, user) %>%
    mutate(sampleid = 0:(nrow(user)-1) ) %>%
    left_join(sample_labels, by = c('userid','trial','sampleid'))  %>%
    # split in epochs of 128 samples 
    # one epoch = 2.56 sec
    mutate(epoch = sampleid %/% 128)
  
  return(user_df)
}
```

- Extract time-domain features from the time-series of a sensor

```{r}
extractTimeDomainFeatures <- function(signals){
  time_df <- 
    signals %>% 
    group_by(userid, trial, epoch) %>%
    summarise(
      # keep track of user and experiment information
      # user_id = userid, 
      # exp_id = trial,   
      # epoch's activity labels, start sample and no. of samples
      activity = most_common_value(c("-", activity)),
      sampleid = sampleid[1],
      n_samples = n(),

      # TODO: Include features here
      m1 = mean(X1), 
      m2 = mean(X2),
      sd1 = sd(X1), 
      q1_25 = quantile(X1, .25),
      skew1 = e1071::skewness(X1),
      peak_x1 = peak(X1),
      peak_x2 = peak(X2),
      peak_x3 = peak(X3),
      freq_mean_x1 = freq_mean(X1),
      freq_mean_x2 = freq_mean(X2),
      freq_mean_x3 = freq_mean(X3),
      freq_var_x1 = freq_var(X1),
      freq_var_x2 = freq_var(X2),
      freq_var_x3 = freq_var(X3)
      
    )  %>%
rename (user_id = userid, exp_id = trial) %>%
ungroup()

  return(time_df)
}
```

- Converts the time-series of a sensor intro a spectral band and extracts frequency-related features

```{r}
extractFreqDomainFeatures <- function(signals){
  freq_signals <- signals
  # TODO: Convert time-series into frequencies
  
  freq_df <-
    freq_signals %>% 
    group_by(userid, trial, epoch) %>%
    summarise(
      # keep track of user and experiment information
      user_id = userid, 
      exp_id = trial,   
      # epoch's activity labels, start sample and no. of samples
      activity = most_common_value(c("-", activity)),
      sampleid = sampleid[1],
      #peak_x1 = peak(X1),
      n_samples = n() #,

      # TODO: Include features here

    ) %>%
rename (user_id = userid, exp_id = trial) %>%
ungroup()
  return(freq_df)
}
```

- This function calls all the previous functions and extracts features from a dataset ("Test" or "Train")

```{r}
extractFeatures <- function(dataset){
  # Get filenames per sensor
  filenames_acc <- dir(paste0("./RawData/", dataset), "^acc", full.names = TRUE)
  filenames_gyr <- dir(paste0("./RawData/", dataset), "^gyr", full.names = TRUE)

  # Extract time-series per sensor
  data_acc <- map_dfr(filenames_acc, extractSignals, sample_labels) 
  data_gyr <- map_dfr(filenames_gyr, extractSignals, sample_labels) 

  # Calculate time-domain features

  time_df <- left_join(extractTimeDomainFeatures(data_acc),
                     extractTimeDomainFeatures(data_gyr),
                     by = c("user_id", "exp_id", "epoch",
                            "activity", "sampleid", "n_samples"),
                     suffix = c("_acc", "_gyr"))
                     

# Calculate frequency-domain features
#freq_df <- left_join(extractFreqDomainFeatures(data_acc),
 #                     extractFreqDomainFeatures(data_gyr),
  #                    by = c("user_id", "exp_id", "epoch","activity", "sampleid", "n_samples"),
   #                   suffix = c("_acc", "_gyr"))
                     
# Merge time_df and freq_df
  output_df <- time_df

  return(output_df)
}

analysis_df <- extractFeatures("Train")

```

# Model fitting

<!----
You should maybe think about the following issues

- What do you do with the unlabelled epochs? That is, the epochs that are marked with `-`?
- For the competition submision you should only provide predictions for the epochs defined in the sample submission file
- Should you remove the epochs that do not consist of 128 samples (i.e., `n â‰  128` in the above data frame)?
--->

- No more epoch with different number of samples after removing the ones without activity

```{r}
analysis_df <- analysis_df %>%
  filter(activity != "-")

analysis_df %>% 
  select(n_samples) %>%
  table()
```

## Model 1
## Model 2
## ....
## Model comparison / selection

- Preliminary feature selection with logistics regression (?)
  - Some discriminant might be untractable / too sensitive with too many variables?

# Submissions

```{r}

testing_df <- extractFeatures("Test")

# TODO: Get predictions from the selected model

```

## Formatting the submission file

To help you turning your predictions into the right format, the following code can help. Here it is executed on the training set data frame, but the same can be applied to the test set data frame.

```{r}
# myData %>%
# 
#     # prepend "user" and "exp" to user_id and exp_id
#     mutate(
#         user_id = paste(ifelse(user_id < 10, "user0", "user"), user_id, sep=""), 
#         exp_id = paste(ifelse(exp_id < 10, "exp0", "exp"), exp_id, sep="")
#     ) %>% 
# 
#     # unit columnes user_id, exp_id and sample_id into a string 
#     # separated by "_" and store it in the new variable `Id`
#     unite(Id, user_id, exp_id, sampleid) %>%
# 
#     # retain only the `Id` and  predictions
#     select(Id, Predicted = activity) %>%
# 
#     # write to file
#     write_csv("test_set_predictions.csv")
# 
# 
# # Check the result: print first 20 lines in the submission file
# cat(readLines("test_set_predictions.csv",20), sep="\n")
```


# DEVELOPING

- We can use this data_frame to develop features

```{r}
develop_df <- extractSignals("./RawData/Train/acc_exp01_user01.txt", sample_labels)

```

```{r}
develop_df %>%
  ggplot(aes(X1)) + 
  geom_histogram(bins=40, fill=1, alpha=0.5) + 
  geom_histogram(aes(X2), bins=40, fill = 2, alpha=0.5) + 
  geom_histogram(aes(X3), bins=40, fill = 4, alpha=0.5) +
  facet_wrap(~activity, scales = "free_y")
```

<!---The histograms are quite distinct, and we can compute all kinds of statistics for them that characterize their shapes (e.g., mean, sd, skewness, inter-quartile ranges, etc.). Hence, useful features may be found amongst these statistical descriptive measures.
-->
