---
title: meh
output: html_document
---
<!-- The ipynb exporter doesn't like the yaml part of the file -->
# Physical activity recognition - Group 6
- David Coba
- Fridtjof Petersen 
- Leonhard Volz

# Setup

```{r}
library(tidyverse) 
library(e1071)
```

```{r}
# Switch to TRUE when submitting the notebook to Kaggle
RUN_IN_KAGGLE <- FALSE
if (RUN_IN_KAGGLE) {
  # Copy all files to the current directory
  system("cp -r ../input/bda-2021-physical-activity-recognition/* ./")
} 
```


## Importing labels

```{r}
act_labels = read_table2("activity_labels.txt", col_names = FALSE)
act_labels = act_labels %>% select(X1,X2)
act_labels 
```

```{r}
labels = read_delim("./RawData/Train/labels_train.txt", " ", col_names = F)
colnames(labels) <- c('trial', 'userid', 'activity', 'start', 'end')

labels = labels %>% mutate(activity = act_labels$X2[activity])
```

```{r}
print(labels)
```

```{r}
# Add the sequence start:end to each row in a list.
# The result is a nested table:
sample_labels_nested <- 
  labels %>% 
  rowwise() %>% # do next operation(s) rowwise
  mutate(sampleid = list(start:end)) %>%
  ungroup()

# Check the resulting table:
print(sample_labels_nested, n=6) 
```

```{r}
sample_labels <- 
  sample_labels_nested %>% 

# Rows are segments, we need to keep track of different segements
mutate(segment = row_number() ) %>% 

# Expand the data frame to one sample per row
unnest(cols = c(sampleid)) %>% 

# Remove columns we don't need anymore
select(-start, -end) 

```

# Features

## Time-domain features

<!---
Slowly changing signals have high autocorellations, while fast changing signals have low or even negative autocorrelations.
https://paper.dropbox.com/doc/Feature-extraction-from-Signals--A62tmtXDMS34X292NP0fKphQAQ-qCp5uvj47gmyuw5nmB8lL
-->

```{r}
lagged_cor <- function(x, y=x, lag=0) {
  # compute correlation between x and a time shifted y
  r_lagged = cor(x, dplyr::lag(y, lag), use='pairwise')
  return(r_lagged)
}
```

## Frequency domain features

<!---
We do not discuss frequency domain features (also known as "spectral" features) at this time, but they are described in the reading materials ([Feature extraction from Signals](https://paper.dropbox.com/doc/Feature-extraction-from-Signals--A62tmtXDMS34X292NP0fKphQAQ-qCp5uvj47gmyuw5nmB8lL)). 
-->
- These function take two inputs:
  - A vector with the different frequencies
  - A vector with the spectral densities

```{r}
peak <- function(freq, spec){
  return(freq[which.max(spec)])
}
```

```{r}
freq_mean <- function(freq, spec){
  df   = freq[2] - freq[1]
  sbar = sum(freq * spec * df)               # 
  return(sbar)  
}
```

```{r}
freq_var <- function(freq, spec){
  df   = freq[2] - freq[1]
  xbar = sum(freq * spec * df)  
  svar = sum((freq - xbar)^2 * spec * df)
  return(svar)  
}
```

# Putting it all together

```{r}
# Helper functions
most_common_value = function(x) {
  counts = table(x, useNA='no')
  most_frequent = which.max(counts)
  if (length(most_frequent) == 0) {
    return(NA)
  }else {
  return(names(most_frequent))
  }
}
```

- Extracts the time-series for the three dimensions of a sensor

```{r}
extractSignals <- function(filename, sample_labels) {
  # extract user and experimental run ID's from file name
  username = gsub(".+user(\\d+).+", "\\1", filename) %>% as.numeric()
  expname  = gsub( ".+exp(\\d+).+", "\\1", filename) %>% as.numeric()
  
  # import the sensor signals from the file
  user <- read_delim(filename, " ", col_names = FALSE, progress = TRUE, 
                     col_types = "ddd")
  # merge signals with labels 
  user_df <- 
    data.frame(userid = username, trial = expname, user) %>%
    mutate(sampleid = 0:(nrow(user)-1) ) %>%
    left_join(sample_labels, by = c('userid','trial','sampleid'))  %>%
    # split in epochs of 128 samples 
    # one epoch = 2.56 sec
    mutate(epoch = sampleid %/% 128)
  
  return(user_df)
}
```

- Extract time-domain features from the time-series of a sensor

```{r}
extractTimeDomainFeatures <- function(signals){
  time_df <- 
    signals %>% 
    group_by(userid, trial, epoch) %>%
    summarise(
      # Epoch's, activity labels, initial sample & no. of samples
      activity = as.factor(most_common_value(c("-", activity))),
      sampleid = sampleid[1],
      n_samples = n(),
      # Features
      # means
      m1 = mean(X1), 
      m2 = mean(X2),
      m3 = mean(X3),
      pw1 = mean(X1^2),
      pw2 = mean(X2^2),
      pw3 = mean(X3^2),
      #standard deviation
      sd1 = sd(X1), 
      sd2 = sd(X2), 
      sd3 = sd(X3), 
      q1_25 = quantile(X1, .25),
      skew1 = e1071::skewness(X1),
      # skew
      skew1 = e1071::skewness(X1),
      skew2 = e1071::skewness(X2),
      skew3 = e1071::skewness(X3),
      # correlation between series
      cor12 = cor(X1, X2, use = "pairwise"),
      cor23 = cor(X2, X3, use = "pairwise"),
      cor13 = cor(X1, X3, use = "pairwise"),
      # auto-/cross-correlation X1
      AR11 = lagged_cor(X1, lag=1),
      AR12 = lagged_cor(X1, X2, lag=1),
      AR13 = lagged_cor(X1, X3, lag=1),
      # auto-/cross-correlation X2
      AR21 = lagged_cor(X2, X1,lag=1),
      AR22 = lagged_cor(X2, lag=1),
      AR23 = lagged_cor(X2, X3, lag=1),
      # auto-/cross-correlation X3
      AR31 = lagged_cor(X3, X1, lag=1),
      AR32 = lagged_cor(X3, X2, lag=1),
      AR33 = lagged_cor(X3, lag=1)
    )  %>%
rename(user_id = userid, exp_id = trial) %>%
ungroup()

  return(time_df)
}
```

- Converts the time-series of a sensor intro a spectral band and extracts frequency-related features

```{r}

# Helper function that tansforms a time-series df into a fft df
spectralDF <- function(df){
  spectral_1 <- spectrum(df[, 1], plot = FALSE)
  spectral_2 <- spectrum(df[, 2], plot = FALSE)
  spectral_3 <- spectrum(df[, 3], plot = FALSE)
  out <- tibble(freq = spectral_1$freq,
                X1 = spectral_1$spec,
                X2 = spectral_2$spec,
                X3 = spectral_3$spec)
  return(out)
}

extractFreqDomainFeatures <- function(signals){
  freq_signals <- signals %>% 
    select(-c(segment, sampleid)) %>%
    group_by(userid, trial, epoch) %>%
    mutate(activity = most_common_value(activity)) %>% 
    ungroup()    %>%
    nest(ts = c(X1, X2, X3)) %>% 
    mutate(ts = map(ts, spectralDF))  %>%
    unnest(cols = c(ts))
  
  freq_df <- freq_signals %>% 
    group_by(userid, trial, epoch) %>%
    summarise(
      # Lables
      activity = as.factor(most_common_value(c("-", activity))),
      # Features
      peak_x1 = peak(freq, X1),
      peak_x2 = peak(freq, X2),
      peak_x3 = peak(freq, X3),
      freq_mean_x1 = freq_mean(freq, X1),
      freq_mean_x2 = freq_mean(freq, X2),
      freq_mean_x3 = freq_mean(freq, X3),
      freq_var_x1 = freq_var(freq, X1),
      freq_var_x2 = freq_var(freq, X2),
      freq_var_x3 = freq_var(freq, X3)
    ) %>%
    ungroup() %>% 
    rename(user_id = userid, exp_id = trial)

  return(freq_df)
}
```

- This function calls all the previous functions and extracts features from a dataset ("Test" or "Train")

```{r}
extractFeatures <- function(dataset){
  # Get filenames per sensor
  filenames_acc <- dir(paste0("./RawData/", dataset), "^acc", full.names = TRUE)
  filenames_gyr <- dir(paste0("./RawData/", dataset), "^gyr", full.names = TRUE)

  # Extract time-series per sensor
  data_acc <- map_dfr(filenames_acc, extractSignals, sample_labels) 
  data_gyr <- map_dfr(filenames_gyr, extractSignals, sample_labels) 

  # Calculate time-domain features
  time_df <- left_join(extractTimeDomainFeatures(data_acc),
                     extractTimeDomainFeatures(data_gyr),
                     by = c("user_id", "exp_id", "epoch",
                            "activity", "sampleid", "n_samples"),
                     suffix = c("_acc", "_gyr"))

# Calculate frequency-domain features
freq_df <- left_join(extractFreqDomainFeatures(data_acc),
                                         extractFreqDomainFeatures(data_gyr),
                                         by = c("user_id", "exp_id", "epoch","activity"),
                     suffix = c("_acc", "_gyr"))
                     
  # Merge time_df and freq_df
  output_df <- left_join(time_df, freq_df,
                         by = c("user_id", "exp_id", "epoch", "activity"))

  return(output_df)
}
```

```{r}
analysis_df <- extractFeatures("Train")
```
# Model fitting

<!----
You should maybe think about the following issues

- What do you do with the unlabelled epochs? That is, the epochs that are marked with `-`?
- For the competition submision you should only provide predictions for the epochs defined in the sample submission file
- Should you remove the epochs that do not consist of 128 samples (i.e., `n â‰  128` in the above data frame)?
--->

- No more epoch with different number of samples after removing the ones without activity

```{r}
analysis_df <- analysis_df %>%
  filter(activity != "-")

analysis_df %>% 
  select(n_samples) %>%
  table()
```

## Model 1 - Naive Bayes classifier
```{r}
analysis_df$activity <- as.factor(analysis_df$activity)
model_naive_bayes <- e1071::naiveBayes(activity ~ m1_acc + m2_acc + m3_acc + sd1_acc + sd2_acc + sd3_acc + skew1_acc + skew2_acc + skew3_acc +
                                         cor12_acc + cor23_acc + cor13_acc +
                                AR11_acc + AR12_acc + AR13_acc + AR21_acc + AR22_acc + AR23_acc + AR11_acc + AR12_acc + AR13_acc +
                                m1_gyr + m2_gyr + m3_gyr + sd1_gyr + sd2_gyr + sd3_gyr + skew1_gyr + skew2_gyr + skew3_gyr +
                                cor12_gyr + cor23_gyr + cor13_gyr +
                                AR11_gyr + AR12_gyr + AR13_gyr + AR21_gyr + AR22_gyr + AR23_gyr + AR11_gyr + AR12_gyr + AR13_gyr, data = analysis_df) 
```

## Model 2
## ....
## Model comparison / selection

- Preliminary feature selection with logistics regression (?)
  - Some discriminant might be untractable / too sensitive with too many variables?

# Submissions

```{r}

testing_df <- extractFeatures("Test")
testing_df$activity <- as.factor(testing_df$activity)
# TODO: Get predictions from the selected model
test_activities <- predict(model_naive_bayes, testing_df)

testing_df <- testing_df %>% mutate(activity = test_activities) 

```


## Formatting the submission file

To help you turning your predictions into the right format, the following code can help. Here it is executed on the training set data frame, but the same can be applied to the test set data frame.

```{r}
output <- testing_df %>%
  # prepend "user" and "exp" to user_id and exp_id
  mutate(
    user_id = paste(ifelse(user_id < 10, "user0", "user"), user_id, sep=""), 
    exp_id = paste(ifelse(exp_id < 10, "exp0", "exp"), exp_id, sep="")
  ) %>% 
  # unit columnes user_id, exp_id and sample_id into a string 
  # separated by "_" and store it in the new variable `Id`
  unite(Id, user_id, exp_id, sampleid) %>%
  # retain only the `Id` and  predictions
  select(Id, Predicted = activity) %>%
  # write to file
  write_csv("test_set_predictions.csv")

head(output)
```

# DEVELOPING

- We can use this data_frame to develop features

```{r}
develop_df <- extractSignals("./RawData/Train/acc_exp01_user01.txt", sample_labels)

```

```{r}
develop_df %>%
  ggplot(aes(X1)) + 
  geom_histogram(bins=40, fill=1, alpha=0.5) + 
  geom_histogram(aes(X2), bins=40, fill = 2, alpha=0.5) + 
  geom_histogram(aes(X3), bins=40, fill = 4, alpha=0.5) +
  facet_wrap(~activity, scales = "free_y")
```

<!---The histograms are quite distinct, and we can compute all kinds of statistics for them that characterize their shapes (e.g., mean, sd, skewness, inter-quartile ranges, etc.). Hence, useful features may be found amongst these statistical descriptive measures.
-->
